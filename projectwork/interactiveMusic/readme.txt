SirenPi

One of the reasons I started this course is to create custom instruments, machines, soundscape generators that are unconventional and tailored to my taste. As I'm in love with lush synthesizer soundscapes, slow filter modulations and raw saw oscillator waveforms, I knew that I had to create something that utilizes these elements according to my liking. I'm interested in cinematic sound design and one of my favourite genres is cyberpunk movies, I wanted to create something that can create soundscapes similar to Blade Runner's Vangelis soundtrack. As this style requires overlapping long sounds, I knew that I had to implement a polyphonic synthesizer.

For user input I decided to utilize the accelerometer sensor as the apartment where we live is made of wood which is very sensitive to all kinds of vibrations, so even a someone walking next on our floor can subtly change the way the soundscape sounds. I also wanted the instrument to be dynamic, so anybody is able to pick it up and play with it, instead of sitting on the shelf. These challanges meant that I had to come up with compromises for the sensor sensitivity and had to finetune it again and again so it's responsive to subtle changes, but not oversensitive. I faced this challange initially when my wife walked next to me while I was changing the code and as she walked over, her footsteps modulated the delay time, causing a heavy detune in the sound. I loved this effect so much, that I decided to incorporate it into the instrument.

For technical requirements, my only requirements were to write good, robust code that I could reuse later. As my coding is really sloppy, I came up with the idea to think how the synth will behave and design it accordingly without writing any code at first. Hence I set down and planned the whole architecture of the synthesizer on paper first. After the original concept was drafted, I sat down and coded the basic multi oscillator engine of the synthesizer. 

As I mentioned I wanted the synth to have polypony and as the garbage collector can create unhappy accidents, I decided to "hardwire" the voices of the synth. This means that I do not dynamically create these objects as the instrument receives clock events, instead we set up the synthesizer once and only modulate the pitch and amplitude once we have the event. As I wanted to create clean, maintainable code, I decided to create these voices as modular as possible, meaning that I want the voices to be separate and if more or less processing power is available, reduce/increment their numbers. This meant that I had to create an array or a list to hold these objects so they can be easily manipulated. I created a list for every component used, but this choice was arbitrary, I could have created a list of voice objects instead, but that would have meant an overhead, which is not required for this small project.

The synthesizer can be separated into three main action blocks: setup, clock events and sensor events. Setup takes care of creating the clock, the sensor object, the glide, oscillator, envelope, gain objects, the filter and the tape delay. For single components the creation of these components can be easily taken care through inline code, but where each voice has a dedicated number of subcomponents this done via a small function. This function takes in all the arrayslists and fills them up with objects, values and takes care of the routing of the objects. This little function can be very useful when dealing with multiple voices, so I'm really sure that I will reuse this block of code in later projects. Some aspects of the setup aren't dynamic, such as the tempo, the key and the scale, which come constants that need to be changed before compilation. However, these changes are really easy to make and no coding skills are required for this. For example, changing the root note from F to D is as easy as changing the KEY constant to 62. Changing the scale is as simple as changin Pitch.minor to Pitch.major or pentatonic.

The sensor listener takes care of processing the changes in the based on the data received from the sensors. This listener is attached to the sensor class to receive continious inputs instead of updating the parameters on clock events. For more computationally expensive instruments, I will probably use that method, but here continuous sensory feedback is more important. The sensor listens to changes on the X, Y and Z axis and maps these changes to the following parameters: delay time in ms, feedback gain, filter cutoff frequency and resonance. 

The clock events take care of generating the notes. The number of ticks is specified as one per beat, to make it easy to work with the clock. The clock is set up based on the tempo which is defined by a constant. On each given clock event, the code grabs the value of the last voice, increments it, divides it by the number of voices and takes the remainder and assigns it as the new voice index. This calculation takes care of the incrementation and the limitation of the voices, so they can only go up to the defined number of maximum voices. After we have the voice that we need to address, we change the value of the corresponding pitch glide to the note value in HZ and set up the gain and an envelope. On the next played note (currently handled by a random number generator) this clock event starts from the beginning, recycling notes that were played earlier.

For the sound, a saw wave oscillator is used, with a low-pass filter to remove unwanted harmonics and a delay to smear the individual notes. During development I tried the sine waveform too, but as it only has one harmonic, the overall effect of the LP filter was almost non-existent, meaning that the interaction would not have as much impact.

For further improvements and changes or even the repurposement of the instrument, one can replace the waveplayers with samplers or gain samplers, creating a modular audio texture machine. If the RPi had the neccessary computational power, using real-time internet resources to provide the audio stream would create an even more interesting, highly interactive instrument.