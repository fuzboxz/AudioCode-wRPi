Network Controlled Music/Audio System
NetDRUM

This assignment was especially hard for me as I'm not really interested in network audio programming, so I had to come up with an idea that was entertaining for me on a personal level and related to network control. Being more interested in traditional traditional hardware instruments, I first decided to create a network based synthesizer for the Raspberry Pi, but the approach failed due to hardware constraints: the garbage collector destroyed the tape delay after some time and polyphony was hopeless as the Pi struggled even with just a few notes. After realizing that my initial approach was a failure, I decided to come up with a new idea. I decided to create a simple network-based sequencable drum machine.

As the Pi is not super powerful, I decided to take a lo-fi approach from the start and implement only a few functions. First I created an OSC listener that takes network triggers from the HappyBrackets plugin. I mapped this listener so it would listen for two addresses for each voice; a complete verb (kick, snare, hihat or crash) and a shortened version (k, s, h or c).  This can be used for testing, triggering single notes manually or when used with a master sequencer triggering several notes in series. Unfortunately, triggering notes this way is not convenient as typing takes a lot of time and network latency causes the notes to not trigger in time.

To circumvent this issue, I implemented a simple pattern playback sequencer which uses strings to trigger notes. To use this sequencer, the user needs to send a “/play” command with a string consisting of k, s, h or c characters. The listener function would take this string and convert it to a character array and parse it one-by-one. If the character matches, the sequencer will trigger the corresponding sound immediately. After each triggered character, the thread sleeps for a specific amount of time based on the internal tempo variable. The restriction of this design is that only a single note can be triggered for a step. This restriction makes harder for the Raspberry Pi to run out of its resources. Controlling the tempo is also done via the OSC interface. The initial tempo is 120 BPM and it can be changed on the fly with the “/tempo” command from the HappyBrackets IntelliJ plugin.

 For the sounds, four different virtual analog algorithms were used. A kick based on sine wave with pitch envelope modulation for the click. The snare is based on a noise oscillator and two sine waves. The hi-hat and the crash both rely on a noise oscillator with different amplitude envelopes to control the length of the release. These sounds are the same ones that I used in the first assignment, so this aspect of the software has been reused.

As I said in the beginning, the network aspect is not something that I’m interested in, however implementing MIDI support and potentiometer-parameter mapping would mean that I could use this instrument as a virtual analog drum machine for sound design.  
